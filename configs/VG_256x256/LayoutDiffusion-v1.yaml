model:
  type: layout_diffusion.layout_diffusion_unet.LayoutDiffusionUNetModel
  parameters:
    reconstruct_object_image: False
    attention_ds_to_reconstruct_object_image: [ 32, 16, 8 ]
    reconstruct_size: 32

    use_fp16: True
    use_scale_shift_norm: True
    in_channels: 3
    out_channels: 6
    model_channels: 256
    encoder_channels: 256 # assert same as layout_encoder.hidden_dim
    num_head_channels: 32
    num_heads: -1
    num_heads_upsample: -1
    num_res_blocks: 2
    resblock_updown: True
    attention_ds: [ 32, 16, 8 ]
    channel_mult: [ 1, 1, 2, 2, 4, 4 ]
    dropout: 0.1
    use_checkpoint: False

    layout_encoder:
      type: layout_diffusion.layout_encoder.LayoutTransformerEncoder
      parameters:
        used_condition_types: [ 'obj_class', 'obj_box' ]
        hidden_dim: 256
        output_dim: 1024 # model_channels x 4
        num_layers: 4
        num_heads: 8
        use_final_ln: True



diffusion:
  type: layout_diffusion.respace.SpacedDiffusion
  parameters:
    model_var_type: "LEARNED_RANGE"
    model_mean_type: "EPSILON"
    diffusion_steps: 1000
    noise_schedule: "linear"
    learn_sigma: True
    timestep_respacing: [ 1000 ]
    loss: "RESCALED_MSE"

schedule_sampler:
  type: layout_diffusion.resample.UniformSampler

data:
  type: 'VG'
  parameters:
    image_size: 256
    layout_length: 12
    num_classes_for_layout_object: 180
    mask_size_for_layout_object: 32
    loader_num_workers: 4
    include_relationships: False
    root_dir: '/workspace/mnt/storage/guangcongzheng/VG'
    vocab_json: 'vocab.json'
    image_dir: 'images'
    max_objects_per_image: 10
    use_orphaned_objects: True
    used_condition_types: [ 'obj_class','obj_box' ]

    train:
      h5_path: 'train.h5'
      max_num_samples: null
      shuffle: True
      batch_size: 4
      left_right_flip: True

    val:
      h5_path: 'val.h5'
      max_num_samples: null
      shuffle: False
      batch_size: 4
      left_right_flip: False

    test:
      h5_path: 'test.h5'
      max_num_samples: 8
      shuffle: False
      batch_size: 4
      left_right_flip: True




train:
  pretrained_model_path: ''
  resume_checkpoint: ''
  classifier_free: True
  classifier_free_dropout: 0.2
  lr: 1e-5
  ema_rate: "0.9999"
  micro_batch_size: 1
  save_interval: 10000
  log_interval: 1000
  log_dir: './log/VG_256x256/LayoutDiffusion-v1'
  use_fp16: True
  fp16_scale_growth: 1e-3
  weight_decay: 0.0
  lr_anneal_steps: 0
  find_unused_parameters: False
  only_update_parameters_that_require_grad: False



sample:
  fix_seed: False
  use_fp16: True
  log_root: '/workspace/mnt/storage/guangcongzheng/zju_zgc_backup/samples/VG_256x256/LayoutDiffusion-v1'
  sample_suffix: 'model0030000'
  pretrained_model_path: './log/VG_256x256/LayoutDiffusion-v1/ema_0.9999_0030000.pt'
  classifier_free: True
  classifier_free_scale: 1.0
  sample_times: 1
  timestep_respacing: [ 1000 ]
  sample_method: 'ddpm'
  clip_denoised: True
  save_imgs_for_visualization: True


