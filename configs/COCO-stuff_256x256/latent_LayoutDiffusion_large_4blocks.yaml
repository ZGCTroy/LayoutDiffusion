model:
  type: layout_diffusion.layout_diffusion_unet.LayoutDiffusionUNetModel
  parameters:
    image_size: 32
    use_fp16: True
    use_scale_shift_norm: True
    in_channels: 4
    out_channels: 8
    model_channels: 192
    encoder_channels: 192 # assert same as layout_encoder.hidden_dim
    num_head_channels: 32
    num_heads: -1
    num_heads_upsample: -1
    num_res_blocks: 2
    num_attention_blocks: 1
    resblock_updown: True
    attention_ds: [ 16, 8, 4, 2, 1 ]
    channel_mult: [ 1, 2, 2, 4, 4 ]
    dropout: 0.0
    use_checkpoint: False
    use_positional_embedding_for_attention: True
    use_key_padding_mask: False
    attention_block_type: 'ObjectAwareCrossAttention'



    layout_encoder:
      type: layout_diffusion.layout_encoder.LayoutTransformerEncoder
      parameters:
        used_condition_types: [
          'obj_class', 'obj_bbox', 'is_valid_obj'
        ]
        hidden_dim: 192
        output_dim: 768 # model_channels x 4
        num_layers: 6
        num_heads: 6
        use_final_ln: True
        use_positional_embedding: False
        resolution_to_attention: [ 2, 4, 8, 16, 32 ]
        use_key_padding_mask: False



diffusion:
  type: layout_diffusion.respace.SpacedDiffusion
  parameters:
    model_var_type: "LEARNED_RANGE"
    model_mean_type: "EPSILON"
    diffusion_steps: 1000
    noise_schedule: "linear"
    learn_sigma: True
    timestep_respacing: [ 1000 ]
    loss: [ "RESCALED_MSE" ]

schedule_sampler:
  type: layout_diffusion.resample.UniformSampler

data:
  type: 'COCO-stuff'
  parameters:
    filter_mode: 'LostGAN'
    use_deprecated_stuff2017: True
    image_size: 256
    layout_length: 10
    num_classes_for_layout_object: 185
    mask_size_for_layout_object: 32
    loader_num_workers: 8
    include_relationships: False
    root_dir: '/workspace/mnt/storage/zhouxianpan/COCO-stuff'
    instance_whitelist: null
    stuff_whitelist: null
    include_other: False
    min_object_size: 0.02
    min_objects_per_image: 3
    max_objects_per_image: 8
    stuff_only: True
    used_condition_types: [ 'obj_class','obj_bbox' ]
    return_origin_image: False

    train:
      image_dir: 'images/train2017'
      instances_json: 'annotations/instances_train2017.json'
      stuff_json: 'annotations/stuff_train2017.json'
      deprecated_stuff_ids_txt: 'annotations/deprecated-challenge2017/train-ids.txt'
      max_num_samples: null
      specific_image_ids: [ ]
      shuffle: True
      batch_size: 16          # 16 GPUs, total_batch_size=16x16=256;
      left_right_flip: True
      use_MinIoURandomCrop: True
    val:
      image_dir: 'images/val2017'
      instances_json: 'annotations/instances_val2017.json'
      stuff_json: 'annotations/stuff_val2017.json'
      deprecated_stuff_ids_txt: 'annotations/deprecated-challenge2017/val-ids.txt'
      max_num_samples: 1024
      specific_image_ids: [ ]
      shuffle: False
      batch_size: 32
      left_right_flip: False
      use_MinIoURandomCrop: False

    test:
      image_dir: 'images/val2017'
      instances_json: 'annotations/instances_val2017.json'
      stuff_json: 'annotations/stuff_val2017.json'
      deprecated_stuff_ids_txt: 'annotations/deprecated-challenge2017/val-ids.txt'
      max_num_samples: null
      specific_image_ids: [ ]
      shuffle: False
      batch_size: 32
      left_right_flip: False
      use_MinIoURandomCrop: False



train:
  vae_root_dir: './pretrained_models/sd-vae-ft-ema'
  latent_diffusion: True
  pretrained_model_path: ''
  resume_checkpoint: '/workspace/mnt/storage/guangcongzheng/zju_zgc/test_for_github/LayoutDiffusion/log/COCO-stuff_256x256/latent_LayoutDiffusion_large_4blocks/model0350000.pt'
  classifier_free: True
  classifier_free_dropout: 0.2
  lr: 5e-5
  ema_rate: "0.9999"
  micro_batch_size: 16 # need 23.5GB memory per GPU
  save_interval: 10000
  log_interval: 1000
  log_dir: './log/COCO-stuff_256x256/latent_LayoutDiffusion_large_4blocks'
  use_fp16: True
  fp16_scale_growth: 1e-3
  weight_decay: 0.0
  lr_anneal_steps: 0
  find_unused_parameters: False
  only_update_parameters_that_require_grad: False



sample:
  fix_seed: True
  use_fp16: True
  log_root: '/workspace/mnt/storage/guangcongzheng/zju_zgc_backup/samples/COCO-stuff_256x256/LayoutDiffusion_large_4blocks'
  sample_suffix: 'model1150000'
  pretrained_model_path: './pretrained_models/COCO-stuff_256x256_LayoutDiffusion_large_ema_1150000.pt'
  classifier_free: True
  classifier_free_scale: 1.0
  sample_times: 1
  timestep_respacing: [ 200 ]
  sample_method: 'ddpm'
  clip_denoised: False
  save_cropped_images: False
  save_images_with_bboxs: False
  save_sequence_of_obj_imgs: False
  adaptive_step_size: False
  rtol: 0.05
  fast_version: True
  eps: 1e-4


